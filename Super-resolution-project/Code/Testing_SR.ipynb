{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing_SR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnzkzzZqbBaMpHlBAqc1w0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dang3tion/Super-resolution-project/blob/main/Super-resolution-project/Code/Testing_SR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG01So5F385J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kfQu_nfk_Rh"
      },
      "source": [
        "# Các bước cần hoàn thành\n",
        "\n",
        "\n",
        "1.   Loading dataset bằng tensorflow, kiểm tra tập dữ liệu thích hợp (các kiểu downsampling bicubic, unknown, realist) \n",
        "2.   Kiểm tra dữ liệu, số lượng, kích cỡ.\n",
        "2.   Tiền xử lý dữ liệu (phân tách tập train, test, val, cấu trúc các dữ liệu, dữ liệu được gán nhãn).\n",
        "1.   Xây dựng các khối ResDense, Convolution, upsampling block.\n",
        "2.   Xây dựng mô hình.\n",
        "3.   Xây dựng các hàm loss.\n",
        "4.   Xử lý dữ liệu trong quá trình training.\n",
        "5.   Training.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h077W1jJk-ZZ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Construct a tf.data.Dataset\n",
        "ds,dsi = tfds.load('div2k/bicubic_x4', split='train',shuffle_files=True,as_supervised=False,with_info=True)\n",
        "\n",
        "# Build your input pipeline\n",
        "tfds.show_examples(ds,dsi,rows=2,cols=2,image_key='hr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk78vqCpkuSb"
      },
      "source": [
        "tf.data.Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_KYpPDNklm1"
      },
      "source": [
        "from tensorflow.data.Dataset import DIV2K\n",
        "\n",
        "train = DIV2K(scale=4, downgrade='bicubic', subset='train')\n",
        "train_ds = train.dataset(batch_size=16, random_transform=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfkUbtUsYKFs"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htReKAN2k9uM"
      },
      "source": [
        ""
      ]
    }
  ]
}